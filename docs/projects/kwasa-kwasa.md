<h1 align="center">Kwasa Kwasa</h1>
<p align="center"><em>There is no reason for your soul to be misunderstood</em></p>

<p align="center">
  <img src="horizontal_film.gif" alt="Logo">
</p>

## The Philosophy Behind Kwasa-Kwasa

Kwasa-Kwasa takes its name from the vibrant musical style that emerged in the Democratic Republic of Congo in the 1980s. During a period when many African nations had recently gained independence, kwasa-kwasa represented a pure form of self-expression that transcended language barriers. Despite lyrics often being in Lingala, the music became immensely popular across Africa because it communicated something universal.

### The Historical Context of Kwasa-Kwasa

In the early 1970s across Africa, leaders faced the rising restlessness of Black youth born after independence. This generation knew nothing of the hardships of war or rural living—they had been born in bustling city hospitals, educated by the continent's finest experts, had disposable income, and free weekends. Music had always been a medium for dancing, but European customs of seated listening were fundamentally misaligned with how music was experienced on the continent.

A musical economy based around drums was logistically and economically infeasible, as these societies lacked the capacity to support a drum industry where children from infancy would consider a drum as an extension of themselves. The breakthrough came when a musician named Kanda Bongo Man broke the rules of soukous (modern "Congolese Rhumba") by making a consequential structural change: he encouraged his guitarist, known as Diblo "Machine Gun" Dibala, the nickname stemming from a rumour that he was abandoned twice at sea as a child, to play solo guitar riffs after every verse.

Just as DJ Kool Herc recognized the potential of extended breaks in "Amen Brother," a mechanic from Kinshasa named Jenoaro saw similar possibilities in these guitar breaks. Some say "kwasa-kwasa" comes from Kikongo for "I am working on it," while others claim it originated from the French phrase "quoi ça" ("what exactly is it?"). But the precise etymology became irrelevant as the dance movement centered on a powerful moral foundation.

In the same way that DJ Kool Herc "invented" sampling and modern dance music, Jenoaro "invented" shifting and all modern dance choreography in Africa. Just as virtually every song in today's charts uses the framework laid out by Herc, there is no dance routine or choreography in modern African music that can exclude kwasa-kwasa.

The dance was intensely physical—deliberately so. In regions where political independence was still a distant dream, kwasa-kwasa became a covert meeting ground for insurgent groups. Instead of clandestine gatherings, people could congregate at venues playing this popular music. Insurgency thus became not just morally justified but something that soothed both soul and body. The lyrics? No one fully understood them, nor did they need to—the souls of the performers were understood without their words being comprehended. Always having five solid reasons to dance, reasons that expert in the fields of philosophy, economics, medicine, psychology and religion, would unanimously affirm, was the problem. A simple solution to a complicated problem. 

Artists like Awilo Longomba, Papa Wemba,Pepe Kale, and Alan Nkuku weren't merely performing—they were expressing their souls in a way that needed no translation. They could be understood without being literally understood. This is the essence of what our framework aims to achieve with text: **ensuring that the soul of your meaning is never misunderstood**.

### The Logo's Meaning

The project's logo shows a sequence of images: a person performing a strange dance, culminating in a confused child watching. This visual metaphor illustrates how expression without proper structure leads to confusion. Even something as seemingly simple as dancing becomes incomprehensible without the right framework for expression.

### Turbulance: More Than a Syntax

The language driving this framework is called "Turbulance"—named with deliberate intent. Information flow is turbulent by nature; meaning emerges from disturbances, whether in air molecules during speech or ink patterns on paper. Turbulance acknowledges that the processes that create meaning have no inherent significance themselves, but they provide the thrust that allows ideas to travel from one mind to another.

### Kwasa-Kwasa Is to Humans What Machine Code Is to Processors

This framework operates at a fundamental level—transforming human language into computational form while preserving its essential meaning. Just as machine code provides processors with direct instructions they can execute, Kwasa-Kwasa transforms natural language into structured semantic units that computers can manipulate algorithmically without losing the "soul" of the original expression.

In some cases, an entire paragraph might be distilled into a single word—not because information is lost, but because the right semantic context allows for such powerful compression of meaning.

## A Metacognitive Text Processing Framework with Turbulance Syntax

Kwasa-Kwasa is a specialized framework designed for writers who need programmatic control over complex text operations with semantic awareness. It combines a powerful text processing language ("Turbulance") with an intelligent orchestration system to create a comprehensive solution for serious writing projects.

---

## Table of Contents

- [Vision](#vision)
- [Core Concepts](#core-concepts)
  - [Turbulance Language](#turbulance-a-language-for-text)
  - [Metacognitive Orchestration](#metacognitive-orchestration)
  - [Proposition and Motion System](#proposition-and-motion-system)
  - [Text Unit System](#text-unit-system)
  - [Hybrid Imperative-Logical-Fuzzy Programming](#hybrid-imperative-logical-fuzzy-programming)
- [System Architecture](#system-architecture)
  - [Core Components](#core-components)
  - [Domain Extensions](#domain-extensions)
- [Installation and Usage](#using-kwasa-kwasa)
- [Real-World Use Cases](#real-world-use-cases)
- [Technology Stack](#technology-stack)
- [Contributing](#contributing)
- [License](#license)

---

## Vision

Kwasa-Kwasa addresses fundamental limitations in how we interact with text. While code has evolved sophisticated tooling for manipulation, refactoring, and analysis, text remains constrained by simplistic word processors or overly complicated publishing workflows.

This project rejects the notion that text should be treated merely as strings or formatting challenges. Instead, it recognizes text as semantically rich units that can be programmatically manipulated while preserving their meaning and context.

> "The way we interact with text hasn't fundamentally changed in decades. Kwasa-Kwasa is not just another text editor or document processor; it's a new paradigm for how writers can leverage computation to enhance their craft. We transform natural language into structured high utility units that allow algorithmic and computational manipulation. Kwasa-kwasa is to humans what machine code is to processors. "

## Core Concepts

### Turbulance: A Language for Text

Turbulance is a domain-specific language designed exclusively for text operations. It provides a rich, expressive syntax for text manipulation with semantic awareness.

#### Key Language Features

- **Boundaries and Text Units**: Define and operate on specific text structures
- **Contextual Transformations**: Apply transformations based on semantic context
- **Knowledge Integration**: Connect with external research sources
- **State Management**: Maintain context across transformations
- **Semantic Operations**: Operate on text while preserving meaning

#### Syntax Example

```turbulance
funxn enhance_paragraph(paragraph, domain="general"):
    within paragraph:
        given contains("technical_term"):
            research_context(domain)
            ensure_explanation_follows()
        given readability_score < 65:
            simplify_sentences()
            replace_jargon()
        return processed
```

#### Language Structure

Turbulance's lexical structure includes:
- **Keywords**: `funxn`, `within`, `given`, `project`, `ensure`, `return`, etc.
- **Operators**: `/` (division), `*` (multiplication), `+` (addition), `-` (subtraction)
- **Control Structures**: Block expressions, conditional execution, iterations
- **Function System**: Declarations, parameters, closures, return values
- **Special Constructs**: `motion`, `proposition`, `cause`, `considering`, `allow`

#### Standard Library

The Turbulance standard library provides built-in functions for text manipulation:

```turbulance
// Text analysis
readability_score(text)              // Returns Flesch-Kincaid score (0-100)
sentiment_analysis(text)             // Returns polarity and subjectivity
extract_keywords(text, count=10)     // Extracts significant keywords

// Text transformation
simplify_sentences(text, level="moderate")  // Simplifies complex sentences
replace_jargon(text, domain="general")      // Replaces specialized terms
formalize(text)                             // Increases formality

// Research assistance
research_context(topic, depth="medium")     // Retrieves contextual information
fact_check(statement)                       // Verifies factual claims
ensure_explanation_follows(term)            // Ensures term is explained

// Utilities
print(value)                                // Outputs to console
len(collection)                             // Returns collection length
typeof(value)                               // Returns type information
```

#### Statistical Analysis Functions
- `ngram_probability(text, sequence, n=3)`: Returns probability of a letter sequence given surrounding context
- `conditional_probability(text, sequence, condition)`: Calculates probability of sequence given conditional context
- `positional_distribution(text, pattern)`: Maps occurrences of pattern across different positions in text
- `entropy_measure(text, window_size=50)`: Calculates information entropy within sliding windows
- `sequence_significance(text, sequence)`: Tests statistical significance of a sequence compared to baseline
- `markov_transition(text, order=1)`: Generates transition probability matrix for text elements
- `zipf_analysis(text)`: Analyzes token frequency distribution against Zipf's law
- `positional_entropy(text, unit="paragraph")`: Measures information distribution across structural units
- `contextual_uniqueness(text, sequence)`: Evaluates how distinctive a sequence is in different contexts

#### Cross-Domain Statistical Analysis
- `motif_enrichment(genomic_sequence, motif)`: Calculates statistical enrichment of genomic motifs
- `spectral_correlation(spectrum1, spectrum2)`: Computes correlation between mass spectral patterns
- `evidence_likelihood(evidence_network, hypothesis)`: Calculates probability of hypothesis given evidence
- `uncertainty_propagation(evidence_network, node_id)`: Models how uncertainty propagates through evidence
- `bayesian_update(prior_belief, new_evidence)`: Updates belief based on new evidence using Bayes' theorem
- `confidence_interval(measurement, confidence_level)`: Calculates confidence intervals for measurements
- `cross_domain_correlation(genomic_data, spectral_data)`: Finds correlations between multi-domain datasets
- `false_discovery_rate(matches, null_model)`: Estimates false discovery rate in pattern matching results
- `permutation_significance(observed, randomized)`: Calculates significance through permutation testing

#### Positional Importance Analysis
- `positional_importance(text, unit="paragraph")`: Calculates importance score based on position within document
- `section_weight_map(document)`: Creates heatmap of importance weights across document sections
- `structural_prominence(text, structure_type="heading")`: Measures text importance based on structural context
- `proximity_weight(text, anchor_points)`: Weights text importance by proximity to key document anchors
- `transition_importance(text)`: Assigns higher importance to text at section transitions or logical boundaries
- `opening_closing_emphasis(text)`: Weights text at the beginning and end of units more heavily
- `local_global_context(text)`: Compares importance of text in its local context versus the entire document
- `hierarchical_importance(document)`: Cascades importance scores through document hierarchy levels
- `citation_proximity(text)`: Weights text based on proximity to citations or evidence
- `rhetorical_position_score(text)`: Assigns scores based on position within rhetorical structures

### Metacognitive Orchestration

The framework doesn't just process text; it understands your goals and guides the writing process through the Metacognitive Orchestrator.

#### Orchestrator Features

- **Goal Representation**: Define and track writing objectives
- **Context Awareness**: Maintain knowledge of document state and domain
- **Intelligent Intervention**: Provide suggestions based on goals and context
- **Progress Evaluation**: Assess alignment with intended outcomes

#### Goal-Oriented Writing

```turbulance
// Setting up a writing goal
var goal = new Goal("Write a technical tutorial for beginners", 0.4)
goal.add_keywords(["tutorial", "beginner", "step-by-step", "explanation"])

// Track progress towards the goal
goal.update_progress(0.3)  // 30% complete
goal.is_complete()         // Returns false

// Evaluating alignment with goals
var alignment = orchestrator.evaluate_alignment(text)
if alignment < 0.3:
    suggest_improvements()
```

#### Advanced Processing Architecture

The Metacognitive Orchestrator implements a streaming-based concurrent processing model with three nested layers:

1. **Context Layer**: Establishes the relevant frame for processing
2. **Reasoning Layer**: Handles logical processing and analytical computation
3. **Intuition Layer**: Focuses on pattern recognition and heuristic reasoning

This architecture enables:
- Processing to begin before complete input is available
- Continuous refinement of results as more information becomes available
- Enhanced ability to handle complex, open-ended tasks

### Proposition and Motion System

Kwasa-Kwasa introduces a paradigm shift from traditional object-oriented programming by replacing classes with **Propositions** that contain **Motions**—pieces of ideas with semantic meaning.

#### Propositions

A Proposition serves as a container for related semantic units:

```turbulance
// Define a proposition with motions
proposition TextAnalysis:
    // Define motions within the proposition
    motion Introduction("The text analysis begins with understanding the context.")
    motion MainPoint("Proper analysis requires both syntactic and semantic understanding.")
    motion Conclusion("By analyzing text with these methods, we gain deeper insights.")
    
    // Add metadata to the proposition
    with_metadata("domain", "linguistics")
    with_metadata("confidence", "0.95")
    
    // Process all motions in this proposition
    considering all motions in this:
        check_spelling(motion)
        check_capitalization(motion)
        
    // Allow specific operations on specific motions
    allow fact_checking on Introduction
    allow coherence_check on Conclusion
```

#### Motions

Motions are the fundamental building blocks within propositions:

```turbulance
// Working with motions directly
motion claim = Motion("Text should be programmatically manipulable", "claim")
motion evidence = Motion("Word processors lack semantic awareness", "evidence")

// Apply motion-specific analysis
spelling_issues = claim.spelling()
capitalization_issues = evidence.capitalization()

// Check for cognitive biases
if claim.check_sunken_cost_fallacy().has_bias:
    print("Warning: Potential sunken cost fallacy detected")
```

#### Specialized Data Structures

The framework introduces data structures specifically for metacognitive text processing and scientific data analysis:

1. **TextGraph**: Represents relationships between text components as a weighted directed graph
2. **ConceptChain**: Represents sequences of ideas with cause-effect relationships
3. **IdeaHierarchy**: Organizes ideas in a hierarchical tree structure
4. **ArgMap**: Creates argumentation maps with claims, evidence, and objections
5. **EvidenceNetwork**: Implements a Bayesian framework for managing conflicting scientific evidence

```turbulance
// Create an evidence network for scientific analysis
var network = new EvidenceNetwork()

// Add nodes representing different types of evidence
network.add_node("genomic_1", EvidenceNode.GenomicFeature {
    sequence: dna_sequence,
    position: "chr7:55249071-55249143",
    motion: Motion("EGFR exon sequence with activating mutation")
})

network.add_node("spectrum_1", EvidenceNode.Spectra {
    peaks: mass_spec_peaks,
    retention_time: 15.7,
    motion: Motion("Mass spectrum showing drug metabolite")
})

// Add edges representing relationships between evidence
network.add_edge("genomic_1", "spectrum_1", EdgeType.Supports { strength: 0.85 }, 0.2)

// Propagate beliefs through the network
network.propagate_beliefs()

// Analyze sensitivity to understand which evidence is most critical
sensitivity = network.sensitivity_analysis("genomic_1")  // Returns impact scores
```

#### Extended Language Syntax

Turbulance includes unique language constructs for text processing:

1. **Considering Statements**: Process collections contextually
   ```turbulance
   considering these paragraphs where contains("important"):
       highlight(paragraph)
   ```

2. **Cause Declarations**: Model relationships between concepts
   ```turbulance
   cause BiasedReasoning = {
       primary: "emotional investment",
       effects: ["selective evidence consideration", "overconfidence in judgment"]
   }
   ```

3. **Allow Statements**: Control permissions for text transformations
   ```turbulance
   allow fact_checking on Abstract
   ```

### Text Unit System

Kwasa-Kwasa's text unit system provides a way to work with text at varying levels of granularity.

#### Unit Hierarchy

The system recognizes multiple levels of text units:
- **Document**: The entire text
- **Section**: Major divisions with headings
- **Paragraph**: Standard paragraph breaks
- **Sentence**: Complete sentences with terminal punctuation
- **Clause**: Grammatical clauses within sentences
- **Phrase**: Meaningful word groups
- **Word**: Individual words
- **Character**: Individual characters

#### Boundary Detection

Text units are identified through:
- Structural markers (headings, paragraph breaks)
- Syntactic analysis (sentence boundaries)
- Semantic coherence (topic-based segmentation)
- User-defined markers (custom delimiters)

#### Working with Text Units

```turbulance
// Process specific unit types
within text as paragraphs:
    // Operate on each paragraph
    print("Found paragraph: " + paragraph)
    
    within paragraph as sentences:
        // Operate on each sentence within this paragraph
        ensure sentences.length < 50  // Ensure sentences aren't too long
```

#### Mathematical Operations on Text

Turbulance enables mathematical-like operations on text:

1. **Division (/)**: Segments text into units
   ```turbulance
   var paragraphs = document / "paragraph"
   var topics = document / "topic"
   ```

2. **Multiplication (*)**: Combines with transitions
   ```turbulance
   var section = historical_context * current_regulations
   ```

3. **Addition (+)**: Combines with connectives
   ```turbulance
   var comprehensive_view = pilot_testimony + expert_analysis
   ```

4. **Subtraction (-)**: Removes elements
   ```turbulance
   var accessible_explanation = technical_explanation - jargon
   ```

#### Transformation Pipelines

Pipelines allow chaining operations for text transformations:

```turbulance
// Basic pipeline with the |> operator
section("Introduction") |>
    analyze_sentiment() |>
    extract_key_themes() |>
    enhance_clarity(level="moderate") |>
    ensure_consistency(with="conclusion")
```

### Hybrid Imperative-Logical-Fuzzy Programming

Kwasa-kwasa extends beyond traditional imperative programming with a powerful hybrid paradigm that incorporates logical programming and fuzzy logic capabilities.

#### Logical Programming Engine

The logical programming engine adds declarative rule-based reasoning to the framework:

```turbulance
// Fact declaration
fact gene("BRCA1").
fact protein("p220").
fact codes_for("BRCA1", "p220").

// Rule declaration
rule gene_produces_protein(Gene, Protein) :-
    gene(Gene),
    protein(Protein),
    codes_for(Gene, Protein).

// Query with variables
query all Protein where gene_produces_protein("BRCA1", Protein)

// Pattern unification
unify sequence("ATGC") with motif(X)
```

This logical approach enables:
- **Declarative Knowledge Representation**: Express domain knowledge as logical rules rather than procedural code
- **Pattern Matching**: Unify variables across domains via pattern matching
- **Constraint Satisfaction**: Define and validate constraints across evidence
- **Non-Monotonic Reasoning**: Handle conflicting evidence and default assumptions

#### Fuzzy Logic System

The fuzzy logic engine provides facilities for representing and reasoning with uncertainty:

```turbulance
// Define linguistic variables
fuzzy_variable gene_expression_level(0.0, 100.0) {
    term low: triangular(0, 0, 30)
    term moderate: triangular(20, 50, 80)
    term high: triangular(70, 100, 100)
}

// Define fuzzy rules
fuzzy_rule gene_expression_rule {
    if gene_expression_level is low then protein_abundance is low with 0.9
}

// Using hedges
fuzzy_rule with_hedges {
    if gene_expression_level is very high and protein_abundance is somewhat low
    then regulation_status is extremely abnormal with 0.7
}
```

The fuzzy logic system enables:
- **Uncertainty Management**: Represent and reason with degrees of belief and fuzzy concepts
- **Linguistic Variables**: Define complex concepts using natural language terms
- **Fuzzy Inference**: Draw conclusions from imprecise evidence
- **Belief Propagation**: Propagate certainty levels through evidence networks

#### Advanced Concepts

The hybrid system introduces several advanced concepts:

1. **Fuzzy Units and Structural Boundaries**: Represents text units with fuzzy boundaries, acknowledging that meaning can span traditional structural boundaries with different degrees of membership.

2. **Contextual Meaning and Interpretation**: Words and concepts carry different meanings in different contexts, and the system models this through context-specific interpretations.

3. **Dreaming Module**: Uses downtime to explore scenarios and develop new rules autonomously, enabling continuous learning and knowledge discovery.

4. **Computational Distribution**: Optimizes performance through intelligent distribution of tasks across different computation types (numerical, logical, fuzzy, pattern matching).

5. **Fuzzy Data Structures**: All data structures can be represented with fuzzy characteristics, including fuzzy containers, maps, graphs, and trees.

## System Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                KWASA-KWASA HYBRID PROGRAMMING FRAMEWORK                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌───────────────────┐                ┌───────────────────────────┐     │
│  │  Imperative       │                │  Logical & Fuzzy Engine   │     │
│  │  Execution Engine │◄──────────────►│  ┌─────────┐ ┌─────────┐  │     │
│  │  (Turbulance)     │                │  │ Logical │ │ Fuzzy   │  │     │
│  └─────────┬─────────┘                │  │ Core    │ │ Core    │  │     │
│            │                          │  └─────────┘ └─────────┘  │     │
│            │                          └───────────┬───────────────┘     │
│            │                                      │                     │
│            ▼                                      ▼                     │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                 Hybrid Reasoning System                          │   │
│  │  ┌────────────────┐ ┌───────────────┐ ┌────────────────────┐    │   │
│  │  │ Evidence       │ │ Rule-Based    │ │ Uncertainty        │    │   │
│  │  │ Network        │ │ Inference     │ │ Management         │    │   │
│  │  └────────────────┘ └───────────────┘ └────────────────────┘    │   │
│  └──────────────────────────────┬──────────────────────────────────┘   │
│                                 │                                       │
│                                 ▼                                       │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                   Domain-Specific Extensions                     │   │
│  ├─────────────┬───────────────┬──────────────┬───────────────┬────┤   │
│  │ Genomic     │ Spectrometry  │ Chemistry    │ Text          │    │   │
│  │ Analysis    │ Analysis      │ Analysis     │ Analysis      │    │   │
│  └─────────────┴───────────────┴──────────────┴───────────────┴────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Core Components

1. **Turbulance Language Engine**
   - Parser and interpreter for Turbulance syntax
   - Compiler to optimize text operations
   - Runtime environment for executing text transformations
   - Standard library of common text functions

2. **Text Unit Processor**
   - Boundary detection for natural text units
   - Hierarchical representation of document structure
   - Transformation pipeline for applying operations
   - State management between operations

3. **Metacognitive Orchestrator**
   - Document goal representation and tracking
   - Contextual understanding of content domains
   - Intervention decision system
   - Progress evaluation against goals

4. **Knowledge Integration Engine**
   - Research interface for contextual information retrieval
   - Knowledge database for storing domain information
   - Citation and reference management
   - Fact verification system
   
5. **Domain Extensions**
   - Genomic sequence analysis for DNA/RNA data
   - Mass spectrometry analysis for experimental data
   - Cheminformatics for molecular structure processing
   - Pattern-based meaning extraction across domains

6. **Logical Programming Engine**
   - Parser for logical facts and rules
   - Unification and pattern matching system
   - Query solver and inference engine
   - Integration with evidence network

7. **Fuzzy Logic Engine**
   - Linguistic variable framework
   - Membership function implementations
   - Fuzzy inference algorithms
   - Defuzzification methods

8. **Hybrid Reasoning System**
   - Combined reasoning across paradigms
   - Domain bridges for different data types
   - Unified query interface
   - Conflict detection and resolution

### Domain Extensions

Kwasa-Kwasa's core philosophy of arbitrarily defined boundaries and semantic unit manipulation extends beyond traditional text processing to other domains, allowing you to work with diverse data types using the same powerful abstractions.

#### Hybrid Evidence Analysis

The hybrid system enables advanced evidence integration and analysis across domains:

```turbulance
import evidence
import logic
import fuzzy
import hybrid

// Create hybrid reasoning system
var hybrid_system = hybrid.HybridReasoningSystem.new()

// Define logical rules
hybrid_system.add_logical_rules([
    "protein_coding_gene(Gene) :- gene(Gene), has_exon(Gene, _)",
    "protein_present(Gene, Sample) :- protein_coding_gene(Gene), peptide_detected(Sample, Peptide), derives_from(Peptide, Gene)",
    "protein_absent(Gene, Sample) :- protein_coding_gene(Gene), not protein_present(Gene, Sample)"
])

// Define fuzzy variables
hybrid_system.add_fuzzy_variable(fuzzy_variable gene_expression(0.0, 100.0) {
    term low: trapezoidal(0, 0, 20, 40)
    term medium: triangular(30, 50, 70)
    term high: trapezoidal(60, 80, 100, 100)
})

// Define fuzzy rules
hybrid_system.add_fuzzy_rule("if gene_expression is high and protein_present is true " +
                           "then evidence_consistency is supporting")

// Apply hybrid reasoning
hybrid_system.apply_logical_rules()
hybrid_system.apply_fuzzy_rules()

// Find contradictions in the evidence
var contradictions = hybrid_system.query(
    "gene(Gene), fuzzy_belief(Gene, 'evidence_consistency', 'contradictory', Degree), Degree > 0.7"
)
```

## Using Kwasa-Kwasa

### Building the Project

To build the Kwasa-Kwasa framework and the Turbulance language:

```bash
# Clone the repository
git clone https://github.com/fullscreen-triangle/kwasa-kwasa.git
cd kwasa-kwasa

# Build the project
cargo build --release
```

The build process will automatically:
1. Generate parser tables for the Turbulance language
2. Create bindings for the standard library functions
3. Generate token definitions and AST serialization code
4. Configure the build based on your target platform

### Running Turbulance Scripts

Once built, you can run Turbulance scripts using the CLI:

```bash
# Run a script
./target/release/kwasa-kwasa run examples/hello_world.turb

# Validate a script
./target/release/kwasa-kwasa validate path/to/script.turb

# Start the REPL
./target/release/kwasa-kwasa repl
```

### Example Turbulance Script

Here's a simple example of a Turbulance script:

```turbulance
funxn analyze_text(text):
    var score = readability_score(text)
    
    within text:
        given score < 60:
            print("Text is complex. Simplifying...")
            simplify_sentences(text, "moderate")
        given score >= 60 and score < 80:
            print("Text has good readability.")
        given score >= 80:
            print("Text is very readable.")
            
    given text.contains("technical_term"):
        ensure_explanation_follows(text, "technical_term")
        
    return text

// Run the analysis on a sample text
var sample = "The technical_term is a specialized concept that requires explanation."
var result = analyze_text(sample)
print(result)
```

### Turbulance Standard Library

The Turbulance language comes with a comprehensive standard library for text processing and analysis:

#### Text Analysis Functions
- `readability_score(text)`: Calculates Flesch-Kincaid readability score (0-100)
- `sentiment_analysis(text)`: Analyzes sentiment polarity and subjectivity
- `extract_keywords(text, count=10)`: Extracts significant keywords from text

#### Text Transformation Functions
- `simplify_sentences(text, level="moderate")`: Simplifies complex sentences
- `replace_jargon(text, domain="general")`: Replaces domain-specific jargon
- `formalize(text)`: Increases formality of text

#### Research Functions
- `research_context(topic, depth="medium")`: Retrieves contextual information
- `fact_check(statement)`: Verifies factual claims
- `ensure_explanation_follows(text, term)`: Ensures term is explained

#### Utility Functions
- `print(value)`: Outputs to console
- `len(collection)`: Returns collection length
- `typeof(value)`: Returns type information
- `json_stringify(value)`: Converts a value to JSON string
- `json_parse(json_string)`: Parses a JSON string into a value
- `time()`: Returns current time as Unix timestamp

## Technology Stack

Kwasa-Kwasa is built with modern, high-performance technologies:

- **Rust** - For memory safety, performance, and concurrency
  - Logos for lexical analysis
  - Chumsky for parsing
  - Memory safety through ownership and borrowing system

- **SQLite** - Embedded database for knowledge storage
  - Zero-configuration, serverless database
  - Efficient for document metadata and knowledge indexing

- **WebAssembly** - For browser integrations
  - Compiled Rust code deployable to browser environments
  - Near-native performance in web applications

- **gRPC** - For efficient service communication
  - High-performance remote procedure calls
  - Multi-language support for system extensions

## Real-World Use Cases

### Genomic Sequence Analysis with Logical Rules

```turbulance
import genomic.high_throughput as ht_genomic
import logic.genomic

// Set up logic for genomic analysis
var rule_base = logic.RuleBase.new()

// Add genomic rules
rule_base.add_rule("functional_region(Gene, Start, End) :- " +
                  "gene(Gene), " +
                  "contains_motif(Gene, 'TATA', Position), " +
                  "Start is Position - 30, " +
                  "End is Position + 5, " +
                  "gc_content_in_range(Gene, Start, End, Content), " +
                  "Content < 0.4.")

// Apply rules to derive new knowledge
rule_base.apply_rules()

// Query for functional regions
var regions = rule_base.query("functional_region(Gene, Start, End)")
```

### Mass Spectrometry Analysis with Fuzzy Logic

```turbulance
import spectrometry.high_throughput as ht_spec
import fuzzy.spectrometry

// Create fuzzy logic engine
var fuzzy_engine = fuzzy.FuzzyLogicEngine.new()

// Define fuzzy rules
fuzzy_engine.add_rule("if peak_intensity is strong and mass_accuracy is high " +
                      "then peptide_identification is high")

// Process spectra
var results = ht_spec.process_spectra_parallel(spectra, (spectrum) => {
    // Find peaks
    var peaks = ht_spec.find_peaks_parallel([spectrum], 500.0, 3.0)[0]
    
    // Apply fuzzy inference
    var result = fuzzy_engine.infer({
        "peak_intensity": fuzzy_engine.fuzzify("peak_intensity", norm_intensity),
        "mass_accuracy": fuzzy_engine.fuzzify("mass_accuracy", mass_accuracy)
    })
    
    // Get peptide identification confidence
    var confidence = result["peptide_identification"]
    
    // Use confidence levels for decision-making
    if confidence["high"] > 0.7 {
        // Accept identification with high confidence
    }
})
```

### Hybrid Evidence Analysis

// ... existing content about evidence analysis...

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on contributing to this project.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
